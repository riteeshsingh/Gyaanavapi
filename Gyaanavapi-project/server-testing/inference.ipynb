{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4093e781e4364776a97a9addb0171064","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["MistralForCausalLM(\n","  (model): MistralModel(\n","    (embed_tokens): Embedding(32000, 4096, padding_idx=2)\n","    (layers): ModuleList(\n","      (0-31): 32 x MistralDecoderLayer(\n","        (self_attn): MistralAttention(\n","          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n","          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n","          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","          (rotary_emb): MistralRotaryEmbedding()\n","        )\n","        (mlp): MistralMLP(\n","          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n","          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n","          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n","          (act_fn): SiLUActivation()\n","        )\n","        (input_layernorm): MistralRMSNorm()\n","        (post_attention_layernorm): MistralRMSNorm()\n","      )\n","    )\n","    (norm): MistralRMSNorm()\n","  )\n","  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",")"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"HuggingFaceH4/zephyr-7b-beta\")\n","model = AutoModelForCausalLM.from_pretrained(\"HuggingFaceH4/zephyr-7b-beta\")\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\snsis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\utils.py:1473: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n","  warnings.warn(\n"]}],"source":["\n","text = \"Your prompt goes here\"\n","encodeds = tokenizer(text, return_tensors=\"pt\", add_special_tokens=False)\n","model_inputs = encodeds.to(device)\n","\n","generated_ids = model.generate(**model_inputs, max_new_tokens=1000, do_sample=True)\n","decoded = tokenizer.batch_decode(generated_ids)\n","\n","print(decoded[0])"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"}},"nbformat":4,"nbformat_minor":2}
